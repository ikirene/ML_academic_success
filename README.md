![Machine Learning Academic Success](https://inoxoft.com/wp-content/uploads/2021/02/Image-1-80-1.jpg)

# MACHINE LEARNING PROJECT (Kaggle Competition)
## **[CLASSIFICATION WITH AN ACADEMIC SUCCESS DATASET](https://www.kaggle.com/competitions/playground-series-s4e6/overview)** 
Este proyecto forma parte de una de las competiciones de Kaggle, la cual se basa en el entrenamiento de modelos de Machine Learning para la predicci贸n del riesgo acad茅mico de los estudiantes en educaci贸n superior. Para abordar este problema, vamos a trabajar con 3 arvchivos (.csv). El primero lo utilizaremos para entrenar nuestros modelos, el segundo para testearlos y el tercero nos servir谩 como herramienta para competir. 

## **DESCRIPCIN DATASET**

El conjunto de datos para esta competencia (tanto de entrenamiento como de prueba) fue generado a partir de un modelo de aprendizaje profundo 
entrenado en el conjunto de datos "Predict Students' Dropout and Academic Success". Las distribuciones de caracter铆sticas son similares, 
pero no exactamente iguales, a las del conjunto de datos original. Si茅ntete libre de utilizar el conjunto de datos original como parte de esta competencia, 
tanto para explorar las diferencias como para ver si incorporar el original en el entrenamiento mejora el rendimiento del modelo. 
Por favor, consulta el conjunto de datos original para obtener explicaciones de las caracter铆sticas.

## **OBJETIVOS DEL PROYECTO**

1. Extraer los datos de forma organizada y 贸ptima.
2. Hacer una lectura de la descripci贸n de las variables obtenidas. 
3. Preprocesamiento de los datos. Aplicamos herramientas y t茅cnicas para preparar los datos seg煤n nuestras necesidades:
   - Observaci贸n y limpieza de valores nulos, si procede.
   - Observaci贸n y clasificaci贸n del tipo de variables (continuas o categ贸ricas).
   - Filtrado de los datos extraidos, selecci贸n de variables y observaci贸n de las correlaciones.
   - Transformaci贸n de diferentes conjuntos de datos.
   - Creaci贸n de funciones que agilicen el preprocesamiento y la implementaci贸n de los modelos.
   - Librer铆as utilizadas: Pandas, Numpy, Seaborn, Sklearn.
   
5. Aplicar modelos de Machine Learning para problemas de clasificaci贸n (DecisionTree, RandomForest, LogisticRegression o KNNeighbors).
6. Evaluar dichos modelos y elegir es m谩s estable.
7. Hacer predicciones con nuestros modelos en base al dataset provisto para el test.
8. Exportar y cargar en Kaggle nuestras predicciones.

## **PREPROCESAMIENTO DE LOS DATOS**

Me encuentro con un _dataset_ con gran cantidad de registros y variables (76518 rows  38 columns). En t茅rminos de variables, podemos hacer las siguientes observaciones:

- En la variable objetivo ('Target') puedo observar que hay 3 categor铆as: Graduate, Dropout y Enrolled. Esto significa que no solo es un problema de clasificaci贸n, sino que adem谩s es multicateg贸rico. Debo tener esto en cuenta a la hora de entrenar y testear mis modelos.
  
- Analizo la relaci贸n entre variables y descartamos aquellas que no aportan demasiado. Por ejemplo, algunas variables aportan informaci贸n irrelevante o redundante, como 'id' o 'International'. Si vemos los porcentajes de 'Nationality', el 99% de los estudiantes son de Portugal (locales), por lo que no tiene sentido conservar la columna 'Interational' que nos indica si el estudiante es local o internacional.
  
- Aplico la t茅cnica OneHotEncoder para obtener los dummies de nuestras variables categ贸ricas. Esta t茅cnica es mucho m谩s viable que la funci贸n .get_dummies, ya que evita posibles problemas en caso de encontrar una categor铆a nueva en el testeo.

## **ENTRENAMIENTO Y TESTEO DE MODELOS**

Una vez tenemos los datos preparados, voy a lanzar dos modelos sencillos y observar el resultado, LogisticRegressor y DecisionTree. Por la naturaleza del algoritmo de DT y su tendencia al _overfitting_ , intuyo que obtendr茅 un mejor resultado con LogisticRegressor con un problema de multicagor铆as como este. A partir de los primeros resultados con cada modelo, la labor consistir谩 en hacer peque帽as modificaciones en los datos y su limpieza para intentar exprimir nuestro modelo al m谩ximo.

## **CONCLUSIONES**

Al realizar este proyecto me di cuenta de la infinidad de modelos que existen para realizar nuestras predicciones. Por el momento en el que hice este proyecto no conoc铆a las herramientas como PyCaret, H20 o Lazy, que me hubieran ayudado a elegir el modelo id贸neo. Sin embargo, veo que lo que marca la diferencia entre una predicci贸n u otra es el proceso de limpieza, preparaci贸n y transformaci贸n de los datos. Si no somos cuidadosos con este proceso, nuestros modelos carecer谩n de la consistencia y fiabilidad necesaria para ser tomados como v谩lidos.












